I had the question "What news source has the most subjectivity in their articles."
So using some libraries I had learned in my computer science class I wrote a program to answer the question.
However, as I was writing this program for class, time ran out and I wrote a program that only took 5 webpages and 
compiled them into a graph.
However, it was not what I wanted the program to be. The compiling time was slow and I really wanted to use less than a hundred lines.
So I just rewrote the algorithm. I first had the user tell the program how many websites they wanted to scrape. 
Then I wrote my original algorithm inside a while loop saying while nor (Number of Rotations) does not equal HM (How Many Websites)
then go through the algorithm.
Then I set up some if statments stating if nor does not equal HM then continue through the algorithm again. Although if they do then 
the program makes a graph based off of the data in the main dataframe where all the data is stored.

